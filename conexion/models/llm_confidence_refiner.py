from conexion.models.base_model import BaseModel
from typing import List, Tuple
from lm_eval.models.huggingface import HFLM
import logging

logger = logging.getLogger(__name__)

class ConfidenceRefinerBasedOnLLM(BaseModel):
    """This model do not extract any keywords, but just reranks the keywords extracted by another model.
    The confidence is calculated based on the probability of the keyword that is generated by the model independently of each other.
    This is a better approach than the ConfidenceBasedLLM class because the probability of the second keyword is not conditioned by the first keyword."""

    def __init__(self, prompt: str, model_name: str):
        """
        Args:
            prompt (str): The prompt to be used for the model.
            model_name (str): The name of the model to be used.
        """
        self.prompt = prompt
        self.model_name = model_name

    def fit(self, abstracts: List[str], keyphrases: List[List[str]]) -> None:
        pass 

    def predict(self, abstracts: List[str], candidate_keywords: List[List[Tuple[str, float]]]) -> List[List[Tuple[str, float]]]:
        # https://blog.eleuther.ai/multiple-choice-normalization/
        confidence_model = HFLM(self.model_name)

        requests = []
        for abstract, keywords in zip(abstracts, candidate_keywords):
            for keyword, k_confidence in keywords:
                requests.append((self.prompt.replace("[DOCUMENT]", abstract), " " + keyword))

        results = confidence_model.loglikelihood(requests)

        resulting_keywords = [(keyword, result[0]) for keyword, result in zip(candidate_keywords, results)]
        return resulting_keywords